% !TeX root = ../main.tex

\chapter{系统实现}
\label{chap:impl}

如\autoref{chap:design}所述，本系统主要由三部分组成：控制器、客户端和存储单元。
他们的实现基于开源的Storage Performence Development Kit (SPDK)~\cite{yang2017spdk}工具和用于网络访问NVMe设备的NVMe-oF~\cite{nvmeof2016}等技术。

\section{控制器}
\label{sec:impl-controller}

本系统的控制器是用Python实现的，其职责是根据用户的请求，为其分配存储单元，并管理存储单元。
控制器通过RPC与客户端库和存储单元通信。
在本系统中，用户和存储单元的SLA曲线被采样后存放在数组中，SLA曲线的加、减等运算都在控制器中通过数组操作实现。
控制器存放着所有数据块的占有状态及从用户的地址空间到存储单元的地址空间的映射。
当需要启用新的存储单元时，控制器通过RPC告知存储服务器上的\JF{加内容}。

由于客户端库直接通过网络访问存储单元，所以为了数据的安全性，需要加入访问控制。
本系统在新租户加入系统时，由控制器生成token同时发送给租户和分配给它的存储单元。
只有当存储单元收到正确的token时，才允许用户进行访问。
在网络传输的过程中，数据被加密，以免数据泄露。

\section{客户端}
\label{sec:impl-client}

客户端：用户态。多线程？如何enforce SLA曲线？
本系统的客户端库也是通过SPDK实现了用户态驱动。

\section{存储单元}
\label{sec:impl-storage-unit}

为了保证系统的低延迟，本系统的存储单元利用SPDK的用户态NVMe驱动进行SSD访问。
SPDK通过绑定CPU核进行轮询，并直接将NVMe队列映射到用户内存空间的方式提高访问效率。
在我们的实验中，1个CPU核就可以跑满Samsung PM963的带宽。
目前的实现利用存储服务器上的DRAM作为写请求的缓冲区。
在SSD的读窗口中，对它的写请求数据直接被存入存储服务器上预先开辟的内存池中。
为了避免读窗口阻塞租户的写队列，存储服务器直接向租户返回写成功的信号。
\JF{有没有什么办法解决consistency？}

\autoref{chap:design}提到，读窗口和写窗口的时长不能被选择得过小，否则过多的窗口切换会影响尾延迟。
\JF{加图}具体描述了同一比例下，不同读写窗口大小对尾延迟的改善程度。
如图所示，当读写窗口的总长度为数十毫秒时，相当于每秒切换窗口数十次，95\%的尾延迟与无读写干扰时相同；
当读写窗口的总长度为数百毫秒时，相当于每秒切换窗口数次，99\%的尾延迟与无读写干扰时相同。
因此，本系统倾向于将读写窗口的总长度限制为数百毫秒。